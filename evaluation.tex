\section{Evaluation}
\label{sec:evaluation}

The following research questions guide our evaluation:
\begin{itemize}
    \item \textbf{RQ1}: Can our approach generate valid proofs?
    \item \textbf{RQ2}: What is the overhead of proof generation during symbolic execution?
    % TODO: proof size?
    \item \textbf{RQ3}: What is the time required to validate the generated proofs?
\end{itemize}

\subsection{Setup}

We use the following modes in our evaluation:
\proofopt is the proof-generating mode, and \base is vanilla \klee.
Each mode is run using the following configuration:
The search heuristic is set to DFS,
the timeout is set to one hour,
the memory limit is set to 4GB,
and the SMT solver is set to STP 2.3.3~\cite{stp}.
In all the modes, we measure the following metrics:
analysis time, number of explored paths, and number of executed instructions.
In the \proofopt mode,
we use \coqc to validate the generated proofs,
and we measure the \emph{proof time}, \ie the time required to compile the proof using \coqc,
and the \emph{proof size}, \ie the size of the compiled proof file (\code{.vo} file) created by \coqc.
We performed our experiments on Ubuntu 24.04,
equipped with Intel Core i9-9900 and 32GB of RAM.

\subsection{Benchmarks}

% TODO: add citations to benchmarks
% TODO: which SE paper uses SVComp?
Our implementation supports memory operations,
so our goal is to evaluate it on programs with memory manipulations.
For this, we selected several benchmarks (\libtasn, \libosip, \coreutils, and \svcomp) that were used in the past in the context of \SE~\cite{klee,symsize-model,klee-rocq}.
In \libtasn and \libosip, we selected a set of APIs,
and for each API we constructed a test driver that runs it with symbolic inputs (integers, arrays, strings, \etc).
To symbolically execute the programs in \coreutils,
one needs to support external calls and model the environment (command-line arguments, file system, \etc).
As our implementation currently does not support these features,
we could not evaluate those programs directly.
However, \coreutils contains a library of APIs, some of which can be tested in isolation.
We selected a subset of such APIs,
and constructed test drivers that run these APIs with symbolic inputs.
In \svcomp, we selected a subset of programs from the \textit{array-memsafety} section.
Most of these programs perform memory allocations with symbolic sizes,
which are currently unsupported by both \klee and our approach.
To overcome this, we modified the relevant parts in these programs to perform fixed-size memory allocations instead.

\subsection{Results}

\begin{figure*}
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/proof-time.pdf}
        %\caption{...}
        %\label{figure:proof-time}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/proof-size.pdf}
        %\caption{...}
        %\label{figure:proof-size}
    \end{subfigure}
    \caption{The proof time (left) and proof size (right) in each subject.}
    \label{figure:proof-results}
\end{figure*}

In this experiment,
we run each subject using the \proofopt and \base modes in order to evaluate the validity and effectiveness of our approach,
The results are discussed below.

\textbf{\text{RQ1.}}
Our approach was able to generate valid proofs for all the programs,
which means that they are safe w.r.t. the concrete \llvm semantics formalized in~\Cref{sec:background}.

\textbf{\text{RQ2.}}
To evaluate the overhead of proof generation during the analysis,
we compare the analysis times of \proofopt and \base.
The average slowdown is 1.34\x and the median slowdown is 1.26\x.
% TODO: why?
The maximum slowdown is obtained in the \textit{strintcmp} API from \coreutils (2.30\x).

\textbf{\text{RQ3.}}
\Cref{figure:proof-results} shows the proof time and the proof size for each subject.
The average and median proof times are 23.1 seconds and 122.9 seconds, respectively.
The average and median proof sizes are approximately 17,000 KB and 5,000 KB, respectively.
In general,
as the number of executed instructions increases,
the size of the generated proof increases as well,
which in turn increases the proof-checking time.
There were two cases (\textit{test\_osip\_hash} and \textit{test\_hash\_pjw}) in which the proof time was rather high despite the number of executed instructions being relatively low.
This was due to the presence of complex SMT array terms in the definitions of the symbolic states and in the application of the interface lemmas for $\tload$ and $\tstore$.
We leave the optimization of such cases for future work.

%\begin{table*}[t]
%\caption{...}
%\label{table:results}
%\centering
%\scriptsize{
%\begin{tabular}{|l|r|r|r|r|r|r|}
%\cline{1-7}
%\multicolumn{1}{|c|}{} &
%\multicolumn{2}{c|}{\textbf{Time}} &
%\multicolumn{1}{c|}{\textbf{Proof Time}} &
%\multicolumn{1}{c|}{\textbf{Proof Size}} &
%\multicolumn{1}{c|}{\textbf{\#Paths}} &
%\multicolumn{1}{c|}{\textbf{\#Inst}} \\
%\cline{2-7}
%\multicolumn{1}{|c|}{} &
%\multicolumn{1}{c|}{\makecell{\textbf{Base}}} &
%\multicolumn{1}{c|}{\makecell{\textbf{PG}}} & & & & \\
%\hline
%A & 0.1 & 0.1 & 1.4 & 1.9 & 4 & 82 \\ \hline
%\end{tabular}
%}
%\end{table*}
