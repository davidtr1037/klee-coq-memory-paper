\section{Evaluation}
\label{sec:evaluation}

The following research questions guide our evaluation:
\begin{itemize}
    \item \textbf{RQ1}: Can our approach generate valid proofs?
    \item \textbf{RQ2}: What is the overhead of proof generation during symbolic execution?
    \item \textbf{RQ3}: What is the cost of validating the generated proofs?
\end{itemize}

\subsection{Setup}

In our evaluation, we use the following modes:
\proofopt is the proof-generating mode, and \base is vanilla \klee.
Each mode is run using the following configuration:
The search heuristic is set to DFS,
the timeout is set to one hour,
and the memory limit is set to 4GB.
%and the SMT solver is set to STP~\cite{stp}.
In all the modes, we measure the following metrics:
analysis time, number of explored paths, and number of executed instructions.
In the \proofopt mode,
we measure the \emph{proof time}, \ie the time required to validate the generated proof using \coqc,
and the \emph{proof size}, \ie the size of the compiled proof file (\code{.vo} file) created by \coqc.
We performed our experiments on Ubuntu 24.04,
equipped with Intel Core i9-9900 and 32GB of RAM.

\subsection{Benchmarks}

Our implementation supports memory operations,
so our goal is to evaluate it on memory-manipulating programs.
For this, we selected several benchmarks (\libtasn~\cite{libtasn1}, \libosip~\cite{libosip}, \coreutils~\cite{coreutils}, and \svcomp~\cite{svcomp-github})
that were used in the past in the context of \SE~\cite{klee,symsize-model,compact-s-e,pinaka,klee-rocq}.
In \libtasn and \libosip, we selected a set of APIs,
and for each API we constructed a test driver that runs it with symbolic inputs (integers, arrays, strings, \etc).
To symbolically execute the programs in \coreutils,
one needs to support external calls and model the environment (command-line arguments, file system, \etc).
As our implementation currently does not support these features,
we could not evaluate those programs directly.
However, \coreutils contains a library of APIs, some of which can be tested in isolation.
We selected a subset of such APIs,
and constructed test drivers that run these APIs with symbolic inputs.
In \svcomp, we selected a subset of programs from the \textit{array-memsafety} section.
Most of these programs perform memory allocations with symbolic sizes,
which are currently unsupported by both \klee and our approach.
To overcome this, we modified the relevant parts in these programs to perform fixed-size memory allocations instead.
In total, our evaluation comprises 42 subjects.\footnote{
A detailed breakdown is given in the appendix (\Cref{appendix:benchmarks}).
}

\subsection{Results}

In this experiment, we evaluate the validity and effectiveness of our approach.
To so do, we run each subject using the \proofopt and \base modes.
The results are discussed below.

\textbf{\text{RQ1.}}
Our approach was able to generate valid proofs for all the subjects,
which means that those programs are safe w.r.t. the concrete \llvm semantics formalized in~\Cref{sec:background}.

\textbf{\text{RQ2.}}
To evaluate the overhead of proof generation during the symbolic execution,
we compare the analysis times of \proofopt and \base.
The results are shown in the scatter plot from~\Cref{figure:time},
where the x-axis and y-axis represent the analysis times with \base and \proofopt, respectively.
The average slowdown is 1.34\x and the median slowdown is 1.26\x.
% TODO: discuss more?
The maximum slowdown is obtained in the \textit{strintcmp} API from \coreutils (2.30\x).

\textbf{\text{RQ3.}}
The scatter plot from~\Cref{figure:proof-time-size} shows the proof time and the proof size for each subject.
The average and median proof times are 23.1 seconds and 122.9 seconds, respectively.
The average and median proof sizes are approximately 20,000 KB and 6,000 KB, respectively.
% TODO: improve
In general,
as the number of executed instructions increases,
the size of the generated proof increases as well,
which in turn results in higher proof time.
There were two cases (\textit{test\_osip\_hash} and \textit{test\_hash\_pjw}) in which the proof time was rather high despite the number of executed instructions being relatively low.
This was due to the presence of complex SMT array terms in the definitions of the symbolic states and in the application of the interface lemmas for $\tload$ and $\tstore$.
We leave the optimization of such cases for future work.

\begin{figure*}
    \centering
    \begin{subfigure}[b]{0.40\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/time.pdf}
        \caption{Analysis time.}
        \label{figure:time}
    \end{subfigure}
    \begin{subfigure}[b]{0.58\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/proof-scatter.pdf}
        \caption{Proof time and proof size.}
        \label{figure:proof-time-size}
    \end{subfigure}
    \hfill
\end{figure*}

%\begin{table*}[t]
%\caption{...}
%\label{table:results}
%\centering
%\scriptsize{
%\begin{tabular}{|l|r|r|r|r|r|r|}
%\cline{1-7}
%\multicolumn{1}{|c|}{} &
%\multicolumn{2}{c|}{\textbf{Time}} &
%\multicolumn{1}{c|}{\textbf{Proof Time}} &
%\multicolumn{1}{c|}{\textbf{Proof Size}} &
%\multicolumn{1}{c|}{\textbf{\#Paths}} &
%\multicolumn{1}{c|}{\textbf{\#Inst}} \\
%\cline{2-7}
%\multicolumn{1}{|c|}{} &
%\multicolumn{1}{c|}{\makecell{\textbf{Base}}} &
%\multicolumn{1}{c|}{\makecell{\textbf{PG}}} & & & & \\
%\hline
%A & 0.1 & 0.1 & 1.4 & 1.9 & 4 & 82 \\ \hline
%\end{tabular}
%}
%\end{table*}
